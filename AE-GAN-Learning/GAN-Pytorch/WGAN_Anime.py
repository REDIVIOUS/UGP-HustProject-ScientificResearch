from __future__ import print_function

import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt

parser = argparse.ArgumentParser()
parser.add_argument('--batchSize', type=int, default=64)
parser.add_argument('--imageSize', type=int, default=64)
parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')
parser.add_argument('--ngf', type=int, default=64)
parser.add_argument('--ndf', type=int, default=64)
parser.add_argument('--epoch', type=int, default=25, help='number of epochs to train for')
# parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')
# parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')
parser.add_argument('--data_path', default='data/faces', help='folder to train data')
parser.add_argument('--outf', default='imgs/WGAN', help='folder to output images and model checkpoints')
opt = parser.parse_args()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 图像读入与预处理
dataset = dset.ImageFolder(root=opt.data_path,
                           transform=transforms.Compose([
                               transforms.Resize(opt.imageSize),  # 缩放图片，保持长宽比不变，最短边为64
                               transforms.CenterCrop(opt.imageSize),  # 中心裁剪，剪出64*64的图
                               transforms.ToTensor(),  # 转换为Tensor
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # 标准化到[-1,1]
                           ]))

dataloader = torch.utils.data.DataLoader(dataset=dataset,
                                         batch_size=opt.batchSize,
                                         shuffle=True,
                                         drop_last=True)


class Generator(nn.Module):
    def __init__(self, ngf, nz):
        super(Generator, self).__init__()
        self.layer1 = nn.Sequential(
            nn.ConvTranspose2d(nz, ngf * 8, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(inplace=True)
        )

        self.layer3 = nn.Sequential(
            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(inplace=True)
        )

        self.layer4 = nn.Sequential(
            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(inplace=True)
        )

        self.layer5 = nn.Sequential(
            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    # 定义NetG的前向传播
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.layer5(out)
        return out


netG = Generator(opt.ngf, opt.nz).to(device)


class Critic(nn.Module):
    def __init__(self, ndf):
        super(Critic, self).__init__()

        self.layer1 = nn.Sequential(
            nn.Conv2d(3, ndf, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(ndf),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.layer3 = nn.Sequential(
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.layer4 = nn.Sequential(
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.layer5 = nn.Sequential(
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            # nn.Sigmoid()
        )

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = self.layer5(out).mean().view(1)
        return out


netD = Critic(opt.ndf).to(device)

n_critic = 3
clip_value = 0.01

# criterion = nn.BCELoss()
optimizerG = torch.optim.RMSprop(netG.parameters(), lr=0.00005)
optimizerD = torch.optim.RMSprop(netD.parameters(), lr=0.00005)

one = torch.FloatTensor(opt.batchSize, 1).zero_()+1
# print(one), print(one.shape)
minus_one = -1*one
# print(minus_one), print(minus_one.shape)

label = torch.FloatTensor(opt.batchSize)
real_label = 1
fake_label = 0

for epoch in range(1, opt.epoch + 1):
    for i, (imgs, _) in enumerate(dataloader):
        # 固定生成器G，训练鉴别器D
        for d_iter in range(n_critic):
            optimizerD.zero_grad()
            for p in netD.parameters():
                p.data.clamp_(-clip_value, clip_value)
            # 让D尽可能的把真图片判别为1
            imgs = imgs.to(device)
            errD_real = netD(imgs)
            label.data.fill_(real_label)
            label = label.to(device)
            errD_real = errD_real.mean(0).view(1)
            errD_real.backward(one.cuda())
            # errD_real = criterion(output, label)
            # errD_real.backward()
            # 让D尽可能把假图片判别为0
            label.data.fill_(fake_label)
            noise = torch.randn(opt.batchSize, opt.nz, 1, 1)
            noise = noise.to(device)
            fake = netG(noise)  # 生成假图
            errD_fake = netD(fake.detach())  # 避免梯度传到G，因为G不用更新
            errD_fake = errD_fake.mean(0).view(1)
            errD_fake.backward(minus_one.cuda())
            # errD_fake = criterion(output, label)
            # errD_fake.backward()
            errD = errD_fake + errD_real
            # Wasserstein_D = errD_real - errD_fake
            optimizerD.step()

        # 固定鉴别器D，训练生成器G
        optimizerG.zero_grad()
        # 让D尽可能把G生成的假图判别为1
        label.data.fill_(real_label)
        label = label.to(device)
        noise = torch.randn(opt.batchSize, opt.nz, 1, 1)
        noise = noise.to(device)
        fake = netG(noise)  # 生成假图
        errG = netD(fake)
        # WGAN 更改
        errG.backward(one.cuda())
        errG = -errG
        # errG = criterion(output, label)
        # errG.backward()
        optimizerG.step()

        if i % 100 == 0:
            print('[%d/%d][%d/%d] Loss_D: %.3f Loss_G %.3f'
                  % (epoch, opt.epoch, i, len(dataloader), errD.item(), errG.item()))

    vutils.save_image(fake.data,
                  '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),
                  normalize=True)
    torch.save(netG.state_dict(), '%s/netG_%03d.pth' % (opt.outf, epoch))
    torch.save(netD.state_dict(), '%s/netD_%03d.pth' % (opt.outf, epoch))



